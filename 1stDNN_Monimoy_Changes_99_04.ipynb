{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1stDNN_Monimoy_Changes_99.04.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/monimoyd/sample_project/blob/master/1stDNN_Monimoy_Changes_99_04.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_P38hI5pMQn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRE_pKeOMloJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDgrP_i6MuAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1xcE5w_M0D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "bca10bf4-954d-4821-8c78-ff7140155710"
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0b97ae07f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADq5JREFUeJzt3X+MVPW5x/H3uriAQFuwCi1pQvTW\nJ7fhDwJRytWlq1Dkkt6rZsGKP2LEhEaLVq/VWEiMYKIE3aD8uE1IFQikEREs0BqjWFNj4u9YbLU+\nVlOJCAQU4QrFFVbuHztsdxbmO7OzZ2aWfT6vfzrnPHvOPI5+en6fb92xY8cQkb7ttFo3ICKVp6CL\nBKCgiwSgoIsEoKCLBNCvSt+jU/silVdXqFB20M1sMfBD2kP8C3d/vdx1iUhllbXrbmY/Ar7v7hOA\nG4ElmXYlIpkq9xh9EvA7AHf/GzDUzL6RWVcikqlygz4C2Ntpem9unoj0QlmddS94EkBEaq/coO8k\nfwv+XWBXz9sRkUooN+jPAtMBzGwssNPdv8isKxHJVF25T6+Z2UJgIvA18HN335b4c11HF6m8gofQ\nZQe9mxR0kcorGHTdAisSgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCC\nLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIu\nEoCCLhKAgi4SgIIuEkC/WjcglfH1118n662trZl+38CBAzl8+HDH9OrVqwv+7aFDh5Lrevfdd5P1\nhx9+OFmfO3du3vTSpUu55ZZbAFi2bFly2YEDBybrLS0tyfpNN92UrNdKWUE3syZgPfBObtZf3P2W\nrJoSkWz1ZIv+J3efnlknIlIxOkYXCaDu2LFj3V4ot+v+v8AHwDBgvrs/l1ik+18iIt1VV7BQZtBH\nAhcBTwDnAC8A/+buXxVYREGvMp2M+5dAJ+MKBr2sY3R3/wRYl5v80Mx2AyOBf5SzPhGprLKO0c3s\nGjP7Ze7zCGA48EmWjYlIdsrddR8C/Bb4FtBA+zH604lFQu66HzhwIFlva2tL1rdt25Y3ffHFF/PC\nCy90TD/77LMFl92/f39y3StWrEjWu6utrY36+vpM1jVq1KhkfdKkScn6o48+mjfdubchQ4Ykl21s\nbEzWH3rooWTdzJL1Cst81/0L4L/KbkdEqkqX10QCUNBFAlDQRQJQ0EUCUNBFAijr8loZ+uTltR07\ndiTrY8aMSdY///zzbn1flpewstad3k47Lb19ee651N3Uxe9e62r8+PG8+uqrAJx99tnJvx08eHCy\nftZZZ3Xru6us4OU1bdFFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUCUNBFAtDrnnvgzDPPTNaHDx+erHf3\nOno1TZkyJVk/2T/7zJkzOz5v3Lix4LL9+/dPrrupqSndXBnGjx+f+TpPJdqiiwSgoIsEoKCLBKCg\niwSgoIsEoKCLBKCgiwSg6+g9UOy56FWrViXrTz75ZLI+YcKEE+Zt2LCh43Nzc3Ny+ZSLLrooWd+0\naVOy3tDQcMK8tWvXdnzevXt3wWUfeeSRIt1J1rRFFwlAQRcJQEEXCUBBFwlAQRcJQEEXCUBBFwlA\n73WvodbW1mS967Xquro6Ov/7mjt3bsFlFy1alFx35+GXT2bixInJuvRKPRs22cxGA5uAxe6+zMy+\nB6wB6oFdwHXunv6vVkRqpuiuu5kNApYCz3eavQBY7u6NwAfArMq0JyJZKOUYvRWYBuzsNK8J2Jz7\nvAWYnG1bIpKlorvu7n4UOGpmnWcP6rSrvgf4TgV66/OKvTvtZOrq/nUY9sADDxT8u1RN4snioZaC\nJwAkTSfjpFrKvbx20MyOP7o1kvzdehHpZcoN+lbg+DOSzcAz2bQjIpVQdNfdzMYBLcAo4IiZTQeu\nAVaZ2c+A7cDqSjbZV/X0GH3o0KFlf/eSJUuS9cbGxpL7kN6vlJNxb9J+lr2rH2fejYhUhG6BFQlA\nQRcJQEEXCUBBFwlAQRcJQI+pnsK++uqrgrWrr746uexTTz2VrG/bti1ZHz16dLIuNVHwmqe26CIB\nKOgiASjoIgEo6CIBKOgiASjoIgEo6CIB6Dp6H7Vv375k/dxzz03Whw0blqxffvnledMtLS3ccccd\nHdMXXnhhwWWvuOKK5Lr1CGzZdB1dJDIFXSQABV0kAAVdJAAFXSQABV0kAAVdJABdRw/qtddeS9an\nTp2arB84cCBvuq2tjfr6+pK++7HHHkvWm5ubk/XBgweX9D0B6Tq6SGQKukgACrpIAAq6SAAKukgA\nCrpIAAq6SABFR1OVvumCCy5I1t95551k/fbbbz9h3owZMzo+r1+/vuCys2bNSq77ww8/TNbvvPPO\nZH3IkCHJekQlBd3MRgObgMXuvszMVgHjgM9yf/Kgu/+hMi2KSE8VDbqZDQKWAs93Kf3K3X9fka5E\nJFOlHKO3AtOAnRXuRUQqpOR73c3sXuDTTrvuI4AGYA8wx90/TSyue91FKq/gve7lnoxbA3zm7n82\ns7uBe4E5Za5LeqFdu3Yl611Pxj3++ONcddVVHdOpk3HFzJs3L1nXybjuKyvo7t75eH0z8Ots2hGR\nSijrOrqZbTCzc3KTTcBfM+tIRDJX9BjdzMYBLcAo4AjwCe1n4e8G/gkcBG5w9z2J1egYvY/58ssv\n86YHDBiQN++VV14puOzkyZOT6y723+T06dOT9XXr1iXrfVj5x+ju/ibtW+2uNvSgIRGpIt0CKxKA\ngi4SgIIuEoCCLhKAgi4SgF73LFXXv3//ZP3o0aPJer9+6YtFb7/9dt60meHuHZ/7ML3uWSQyBV0k\nAAVdJAAFXSQABV0kAAVdJAAFXSQAve5ZTmrnzvQrAjdu3Jg3PWfOHJYtW9Yx/fLLLxdctth18mLO\nP//8ZP28884raV4k2qKLBKCgiwSgoIsEoKCLBKCgiwSgoIsEoKCLBKDn0fuovXv3JuvLly9P1leu\nXJms79ixI2+6ra2N+vr60poroth6rrzyymR97dq1mfRxCtLz6CKRKegiASjoIgEo6CIBKOgiASjo\nIgEo6CIB6Hn0XuzgwYN504MHD86bt2XLloLLLliwILnu999/v2fN9cAll1ySrC9cuDBZHzduXJbt\nhFBS0M1sEdCY+/sHgNeBNUA9sAu4zt1bK9WkiPRM0V13M7sYGO3uE4CpwMPAAmC5uzcCHwCzKtql\niPRIKcfoLwIzcp/3A4OAJmBzbt4WYHLmnYlIZrp1r7uZzaZ9F/5Sdz87N+9cYI27/0diUd3rLlJ5\nBe91L/lknJldBtwITAH+XsrKpWdOpZNx3XmoRSfjqq+ky2tmdikwD/hPdz8AHDSzgbnySCD9ylAR\nqamiW3Qz+ybwIDDZ3fflZm8FmoG1uf99pmIdnsIOHTqUrH/88cfJ+rXXXps3/cYbb9DU1NQx/dZb\nb5XdW09NmTIlOW/+/PkFly32uua6Ou0kZq2UXfefAt8Gnug0tvT1wG/M7GfAdmB1ZdoTkSwUDbq7\nrwBWnKT04+zbEZFK0C2wIgEo6CIBKOgiASjoIgEo6CIB6HXPRRw+fLhg7bbbbksu+9JLLyXr7733\nXrd6yfKVytOmTUvW77nnnmR9zJgxedOnn346R44cyZuWqtPrnkUiU9BFAlDQRQJQ0EUCUNBFAlDQ\nRQJQ0EUC6POve/7oo4+S9fvvvz9vesWKFcyePbtjeuvWrQWX3b59e49666kzzjijYO2+++5LLnvz\nzTcn6w0NDd3uR9fOey9t0UUCUNBFAlDQRQJQ0EUCUNBFAlDQRQJQ0EUC6PPPo7e0tCTrd911V950\nls98jx07NlmfOXNmst6vX/5tDrfeeitLlizpmO58vb+rAQMGlNCh9DF6Hl0kMgVdJAAFXSQABV0k\nAAVdJAAFXSQABV0kgJKuo5vZIqCR9ufXHwD+GxgHfJb7kwfd/Q+JVZyy73UXOYUUvI5e9MUTZnYx\nMNrdJ5jZmcBbwB+BX7n777PrUUQqpZQ3zLwIvJb7vB8YBGRz65iIVEW3boE1s9m078K3ASOABmAP\nMMfdP00sql13kcrr+S2wZnYZcCMwB1gD3O3ulwB/Bu7tYYMiUkElvRzSzC4F5gFT3f0A8Hyn8mbg\n1xXoTUQyUnSLbmbfBB4EfuLu+3LzNpjZObk/aQL+WrEORaTHStmi/xT4NvCEmR2ftxJYZ2b/BA4C\nN1SmPRHJQp9/Hl0kED2PLhKZgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4SgIIuEoCCLhKAgi4S\ngIIuEoCCLhKAgi4SQElvmMlAwcfnRKTytEUXCUBBFwlAQRcJQEEXCUBBFwlAQRcJQEEXCaBa19E7\nmNli4Ie0vwL6F+7+erV7OBkzawLWA+/kZv3F3W+pXUdgZqOBTcBid19mZt+jfTisemAXcJ27t/aS\n3lbRvaG0K9lb12G+X6cX/G4ZDD9etqoG3cx+BHw/NwTzvwOPAROq2UMRf3L36bVuAsDMBgFLyR/+\nagGw3N3Xm9n9wCxqMBxWgd6gFwylXWCY7+ep8e9W6+HHq73rPgn4HYC7/w0YambfqHIPp4pWYBqw\ns9O8JtrHugPYAkyuck/Hnay33uJFYEbu8/Fhvpuo/e92sr6qNvx4tXfdRwBvdprem5v3f1Xuo5Af\nmNlmYBgw392fq1Uj7n4UONppGCyAQZ12OfcA36l6YxTsDWCOmf0PpQ2lXane2oBDuckbgaeBS2v9\nuxXoq40q/Wa1PhnXm+6B/zswH7gMuB541MwaattSUm/67aCXDaXdZZjvzmr6u9Vq+PFqb9F30r4F\nP+67tJ8cqTl3/wRYl5v80Mx2AyOBf9SuqxMcNLOB7n6Y9t56za6zu/eaobS7DvNtZr3id6vl8OPV\n3qI/C0wHMLOxwE53/6LKPZyUmV1jZr/MfR4BDAc+qW1XJ9gKNOc+NwPP1LCXPL1lKO2TDfNNL/jd\naj38eLVGU+1gZguBicDXwM/dfVtVGyjAzIYAvwW+BTTQfoz+dA37GQe0AKOAI7T/n841wCpgALAd\nuMHdj/SS3pYCdwMdQ2m7+54a9Dab9l3g9zvNvh74DTX83Qr0tZL2XfiK/2ZVD7qIVF+tT8aJSBUo\n6CIBKOgiASjoIgEo6CIBKOgiASjoIgH8P1xSBdWeVoXpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0c04557320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rnVBLQ0oM3tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ME3NIhU7M-tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CL4cTsEDNIVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f0dec48-e5e5-43d2-c3de-37cb70e1f3fa"
      },
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "r7Xc2UoLNPUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lT78J18NTcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "80a849a1-d6f0-45c2-861e-ba4dcaaf7ce8"
      },
      "cell_type": "code",
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "1kCv2_NvNYmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "522bf3ec-39d8-482c-957f-0c112c7a03ba"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 1, activation='relu'))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(16, 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Convolution2D(10, 1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tq3yh3-yNeXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "86753f2b-0823-4c4c-8ec7-e6177f307130"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 26, 26, 32)        2080      \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 16)        528       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 10, 10, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 2, 2, 10)          910       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 1, 1, 10)          110       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 18,736\n",
            "Trainable params: 18,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sfd5_mlNNlZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJMBN1neNp1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5557
        },
        "outputId": "9297f437-c757-4e62-b408-b0c6d1ae598c"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=150, verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 2.1713 - acc: 0.1795\n",
            "Epoch 2/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 1.3537 - acc: 0.5022\n",
            "Epoch 3/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.8041 - acc: 0.7478\n",
            "Epoch 4/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.4866 - acc: 0.8600\n",
            "Epoch 5/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.3482 - acc: 0.8977\n",
            "Epoch 6/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.2870 - acc: 0.9151\n",
            "Epoch 7/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.2476 - acc: 0.9266\n",
            "Epoch 8/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.2166 - acc: 0.9355\n",
            "Epoch 9/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.1972 - acc: 0.9405\n",
            "Epoch 10/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.1716 - acc: 0.9481\n",
            "Epoch 11/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.1585 - acc: 0.9520\n",
            "Epoch 12/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.1512 - acc: 0.9543\n",
            "Epoch 13/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1384 - acc: 0.9576\n",
            "Epoch 14/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1270 - acc: 0.9611\n",
            "Epoch 15/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.1223 - acc: 0.9623\n",
            "Epoch 16/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1166 - acc: 0.9639\n",
            "Epoch 17/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1117 - acc: 0.9655\n",
            "Epoch 18/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.1109 - acc: 0.9660\n",
            "Epoch 19/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.1013 - acc: 0.9688\n",
            "Epoch 20/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0962 - acc: 0.9704\n",
            "Epoch 21/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0924 - acc: 0.9712\n",
            "Epoch 22/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0897 - acc: 0.9726\n",
            "Epoch 23/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0878 - acc: 0.9728\n",
            "Epoch 24/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0833 - acc: 0.9742\n",
            "Epoch 25/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0824 - acc: 0.9746\n",
            "Epoch 26/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0800 - acc: 0.9754\n",
            "Epoch 27/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0755 - acc: 0.9768\n",
            "Epoch 28/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0749 - acc: 0.9771\n",
            "Epoch 29/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0753 - acc: 0.9769\n",
            "Epoch 30/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0737 - acc: 0.9773\n",
            "Epoch 31/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0687 - acc: 0.9791\n",
            "Epoch 32/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0647 - acc: 0.9805\n",
            "Epoch 33/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0654 - acc: 0.9799\n",
            "Epoch 34/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0629 - acc: 0.9803\n",
            "Epoch 35/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0603 - acc: 0.9818\n",
            "Epoch 36/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0609 - acc: 0.9815\n",
            "Epoch 37/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0574 - acc: 0.9825\n",
            "Epoch 38/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0600 - acc: 0.9815\n",
            "Epoch 39/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0554 - acc: 0.9827\n",
            "Epoch 40/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0536 - acc: 0.9835\n",
            "Epoch 41/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0529 - acc: 0.9840\n",
            "Epoch 42/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0597 - acc: 0.9811\n",
            "Epoch 43/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0552 - acc: 0.9827\n",
            "Epoch 44/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0525 - acc: 0.9837\n",
            "Epoch 45/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0518 - acc: 0.9837\n",
            "Epoch 46/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0486 - acc: 0.9853\n",
            "Epoch 47/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0462 - acc: 0.9856\n",
            "Epoch 48/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0479 - acc: 0.9845\n",
            "Epoch 49/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0465 - acc: 0.9855\n",
            "Epoch 50/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0451 - acc: 0.9860\n",
            "Epoch 51/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0489 - acc: 0.9844\n",
            "Epoch 52/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0473 - acc: 0.9852\n",
            "Epoch 53/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0447 - acc: 0.9864\n",
            "Epoch 54/150\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.0459 - acc: 0.9855\n",
            "Epoch 55/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0451 - acc: 0.9858\n",
            "Epoch 56/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0436 - acc: 0.9865\n",
            "Epoch 57/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0423 - acc: 0.9867\n",
            "Epoch 58/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0432 - acc: 0.9864\n",
            "Epoch 59/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0414 - acc: 0.9871\n",
            "Epoch 60/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0385 - acc: 0.9877\n",
            "Epoch 61/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0396 - acc: 0.9874\n",
            "Epoch 62/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0415 - acc: 0.9864\n",
            "Epoch 63/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0414 - acc: 0.9867\n",
            "Epoch 64/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0382 - acc: 0.9880\n",
            "Epoch 65/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0376 - acc: 0.9882\n",
            "Epoch 66/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0385 - acc: 0.9880\n",
            "Epoch 67/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0386 - acc: 0.9882\n",
            "Epoch 68/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0357 - acc: 0.9890\n",
            "Epoch 69/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0398 - acc: 0.9871\n",
            "Epoch 70/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0416 - acc: 0.9866\n",
            "Epoch 71/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0364 - acc: 0.9887\n",
            "Epoch 72/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0342 - acc: 0.9892\n",
            "Epoch 73/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0352 - acc: 0.9889\n",
            "Epoch 74/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0331 - acc: 0.9900\n",
            "Epoch 75/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0378 - acc: 0.9881\n",
            "Epoch 76/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0330 - acc: 0.9894\n",
            "Epoch 77/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0327 - acc: 0.9896\n",
            "Epoch 78/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0315 - acc: 0.9903\n",
            "Epoch 79/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0325 - acc: 0.9894\n",
            "Epoch 80/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0315 - acc: 0.9899\n",
            "Epoch 81/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0299 - acc: 0.9906\n",
            "Epoch 82/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0306 - acc: 0.9902\n",
            "Epoch 83/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0334 - acc: 0.9895\n",
            "Epoch 84/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0295 - acc: 0.9906\n",
            "Epoch 85/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0294 - acc: 0.9909\n",
            "Epoch 86/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0311 - acc: 0.9896\n",
            "Epoch 87/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0310 - acc: 0.9904\n",
            "Epoch 88/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0309 - acc: 0.9903\n",
            "Epoch 89/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0268 - acc: 0.9914\n",
            "Epoch 90/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0276 - acc: 0.9917\n",
            "Epoch 91/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0280 - acc: 0.9910\n",
            "Epoch 92/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0302 - acc: 0.9901\n",
            "Epoch 93/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0298 - acc: 0.9905\n",
            "Epoch 94/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0280 - acc: 0.9913\n",
            "Epoch 95/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0289 - acc: 0.9906\n",
            "Epoch 96/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0297 - acc: 0.9903\n",
            "Epoch 97/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0258 - acc: 0.9920\n",
            "Epoch 98/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0266 - acc: 0.9917\n",
            "Epoch 99/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0268 - acc: 0.9916\n",
            "Epoch 100/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0266 - acc: 0.9917\n",
            "Epoch 101/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0280 - acc: 0.9908\n",
            "Epoch 102/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0257 - acc: 0.9918\n",
            "Epoch 103/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0250 - acc: 0.9923\n",
            "Epoch 104/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0241 - acc: 0.9923\n",
            "Epoch 105/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0244 - acc: 0.9921\n",
            "Epoch 106/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0243 - acc: 0.9926\n",
            "Epoch 107/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0230 - acc: 0.9928\n",
            "Epoch 108/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0238 - acc: 0.9924\n",
            "Epoch 109/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0227 - acc: 0.9928\n",
            "Epoch 110/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0233 - acc: 0.9926\n",
            "Epoch 111/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0230 - acc: 0.9930\n",
            "Epoch 112/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0233 - acc: 0.9924\n",
            "Epoch 113/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0212 - acc: 0.9932\n",
            "Epoch 114/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0222 - acc: 0.9929\n",
            "Epoch 115/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0214 - acc: 0.9932\n",
            "Epoch 116/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0238 - acc: 0.9923\n",
            "Epoch 117/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0216 - acc: 0.9931\n",
            "Epoch 118/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0232 - acc: 0.9928\n",
            "Epoch 119/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0216 - acc: 0.9930\n",
            "Epoch 120/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0252 - acc: 0.9917\n",
            "Epoch 121/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0199 - acc: 0.9941\n",
            "Epoch 122/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0211 - acc: 0.9931\n",
            "Epoch 123/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0199 - acc: 0.9939\n",
            "Epoch 124/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0211 - acc: 0.9932\n",
            "Epoch 125/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0212 - acc: 0.9931\n",
            "Epoch 126/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0190 - acc: 0.9942\n",
            "Epoch 127/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0195 - acc: 0.9942\n",
            "Epoch 128/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0193 - acc: 0.9938\n",
            "Epoch 129/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0218 - acc: 0.9929\n",
            "Epoch 130/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0245 - acc: 0.9920\n",
            "Epoch 131/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0220 - acc: 0.9929\n",
            "Epoch 132/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0178 - acc: 0.9943\n",
            "Epoch 133/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0186 - acc: 0.9943\n",
            "Epoch 134/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0194 - acc: 0.9935\n",
            "Epoch 135/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0178 - acc: 0.9942\n",
            "Epoch 136/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0205 - acc: 0.9933\n",
            "Epoch 137/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0200 - acc: 0.9936\n",
            "Epoch 138/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0181 - acc: 0.9941\n",
            "Epoch 139/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0201 - acc: 0.9937\n",
            "Epoch 140/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0194 - acc: 0.9935\n",
            "Epoch 141/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0191 - acc: 0.9941\n",
            "Epoch 142/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0177 - acc: 0.9944\n",
            "Epoch 143/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0171 - acc: 0.9948\n",
            "Epoch 144/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0176 - acc: 0.9944\n",
            "Epoch 145/150\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0148 - acc: 0.9956\n",
            "Epoch 146/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0169 - acc: 0.9946\n",
            "Epoch 147/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0203 - acc: 0.9933\n",
            "Epoch 148/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0165 - acc: 0.9949\n",
            "Epoch 149/150\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0155 - acc: 0.9951\n",
            "Epoch 150/150\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0178 - acc: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b97ae0d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "nvM-hwREP3Uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpW9QYCjQBEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37ac2c89-3755-4772-849e-cc49873c2ca2"
      },
      "cell_type": "code",
      "source": [
        "print(score)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03839287002871497, 0.9891]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTo3owzcQIwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8pvBUe3QOE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}